# -*- coding: utf-8 -*-
"""UNI-DCIES2025-MAEB-TrabajoFinal-Nowcasting-MCMC-Nuts-Python-v01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1idP91xT4ghY_9ynFUHTf9GY4IW8prfN4
"""



"""```
# ================================================================================================================
# UNI - DCIES 2025 - Curso: Modelos Avanzados de Estadística Bayesiana
#     Tema:           Trabajo Final 1 - Nowcasting de Casos de E. Coli en Alemania usando MCMC (HMC/NUTS)
#     Profesor:       Dr. Erick Chacon Montalvan
#     Autor:          Juan Carlos Tovar Ueda
#     Fecha:          Enero 2026
#     Descripción:    Implementación de un modelo bayesiano para nowcasting de casos de E. coli
#                     utilizando PyMC y MCMC (HMC/NUTS). El modelo estima la tasa real de casos
#                     diarios considerando retrasos en el reporte.
# ===============================================================================================================\
```


"""

import pandas as pd
import numpy as np
import pymc as pm
import arviz as az
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

# Funcion de Preparación de Datos (cargar CSV y transformar en parametros de salida de datos)
#    Entrada:   archivo_csv:    Ruta y nombre del archivo.
#               fecha_actual:   Fecha de tope del calculo.
#    Salida:    observaciones:  Matriz de observaciones (dataset), que contiene los siguientes campos:
#                                   'date':               Fecha de ocurrencia (YYYY-MM-DD)
#                                   't_idx':              Dia de ocurrencia (se correlaciona con date)
#                                   'd_idx':              Dias de retraso (a partir del dia de ocurrencia)
#                                   'casos_observados':   Total de casos observados en dicho retraso
#               t_len:          Numero de dias de ocurrencia (filas)
#               d_len:          Numero de delays por ocurrencias (ej. 16)
#               date:           Vector de fechas (desde el inicio hasta el fin)
# -------------------------------------------------------------------------------------------------------------
def cargar_preparar_datos(archivo_csv, fecha_actual=None):

    # Cargar datos acumulados, le coloco como cabecera el nombre 'date'
    # a la primera columna, luego convierto su contenido a formato fecha
    df = pd.read_csv(archivo_csv)
    df.rename(columns={'Unnamed: 0': 'date'}, inplace=True)
    df['date'] = pd.to_datetime(df['date'])

    # Extraer matriz de reportes acumulados (Y_cum)
    # Filas: Días de ocurrencia (t), Columnas: Días de retraso (d)
    # Aqui solo extraemos los datos de delay (no extraeremos los dias)
    Y_cum = df.filter(like='delay').values

    # Convertir de Acumulado a Incidental - Independiente (Y_inc)
    # n(t, d) = N(t, d) - N(t, d-1)
    # Esto es, pasar de una Frecuencia Acumulada a una Frecuencia Absoluta por dias.
    Y_inc = np.zeros_like(Y_cum)
    Y_inc[:, 0] = Y_cum[:, 0]
    Y_inc[:, 1:] = np.diff(Y_cum, axis=1)

    # Definir fecha de corte "Now" (fecha_actual): Simulación de tiempo real
    # Si no se define, usamos la última fecha del dataset
    if fecha_actual is None:
        fecha_actual = df['date'].iloc[-1]

    # Crear estructura para el modelo (Long Format)
    # Solo mantenemos datos donde (fecha_ocurrencia + retraso) <= fecha_actual
    observaciones = []
    t_len, d_len = Y_inc.shape
    for t_idx in range(t_len):  #-- Se recorren las filas
        date_t = df['date'].iloc[t_idx]
        for d_idx in range(d_len):   #-- Se recorren las columnas por cada fila
            date_report = date_t + pd.Timedelta(days=d_idx)
            # Condición de Nowcasting: ¿El reporte ya ocurrió?
            if date_report <= fecha_actual:
                observaciones.append({
                    'date': date_t,   #-- Fecha de ocurrencia (YYYY-MM-DD)
                    't_idx': t_idx,   #-- Dia de ocurrencia (se correlaciona con date)
                    'd_idx': d_idx,   #-- Dias de retraso (a partir del dia de ocurrencia)
                    'casos_observados': int(Y_inc[t_idx, d_idx])
                })

    return pd.DataFrame(observaciones), t_len, d_len, df['date']

# Probar la Funcion de Preparación de Datos (para describir el contenido)

from google.colab import drive
# drive.mount('/content/drive')

# Define the path to your CSV file in Google Drive.
# IMPORTANT: Please update 'your_e_coli_data.csv' with the actual filename.
csv_filename = '/content/drive/MyDrive/Colab Datasets/husO104_tri_cumu.csv'

# Invoke the load_and_prep_data function
observations_df, t_len, d_len, dates = cargar_preparar_datos(csv_filename)

print(f"--- REVISION DE LOS DATOS REALES ---")
print(dates)
print(f"Se cargaron {len(observations_df)} observaciones.")
print(f"N° de dias de ocurrencia (filas): t_len: {t_len}")
print(f"N° de dias de atraso (delay) d_len: {d_len}")
print("Cabecera de Observaciones del DataFrame:")
print(observations_df.head(30))
print(observations_df.tail(20))

# Funcion de Generacion de Datos Sintéticos (Simulación de Monte Carlo)
# -------------------------------------------------------------------------------------------------------------
# Esta función actúa como el "Generador de la Verdad" (Ground Truth), creando un escenario controlado
# para validar si el algoritmo HMC/NUTS es capaz de recuperar parámetros conocidos.
#
# Entrada:
#    n_days:    int. Número total de días de la serie temporal epidémica (T).
#    n_delays:  int. Retraso máximo permitido para el reporte de casos (D).
#    b_true:    float. Valor real de la Tasa de Retraso (Decay Rate) que el modelo debe estimar.
#    phi_true:  float. Valor real de la Probabilidad de Reporte Inmediato (Eficiencia Inicial).
#
# Salida:
#    df_sintetico: pd.DataFrame. Triángulo de reporte en formato 'Long', filtrado por la condición
#                                de nowcasting (solo datos ocurridos antes del "ahora").
#    lambda_true:  np.array. La curva real de incidencia (intensidad) que se intentará predecir.
#    b_true:       float. Parámetro de velocidad original.
#    phi_true:     float. Parámetro de eficiencia original.
# -------------------------------------------------------------------------------------------------------------
def generar_datos_sinteticos(n_days=60, n_delays=16, b_true=0.15, phi_true=0.2):
    # Genera un triángulo de reportes sintético donde conocemos la 'verdad'.
    np.random.seed(42) # Para que los resultados sean siempre iguales

    # 1. Definimos la verdad: Una curva epidémica (lambda_t) tipo campana
    t = np.linspace(0, 1, n_days)
    # Creamos una curva que sube y baja (usando una PDF de una normal como ejemplo)
    lambda_true = 50 * np.exp(-(t - 0.5)**2 / (2 * 0.1**2))

    # 2. Definimos el retraso: Usamos tu fórmula paramétrica (Ecuación 2)
    d_vals = np.arange(n_delays)
    p_d_cum = 1 - (1 - phi_true) * np.exp(-b_true * d_vals)

    # Obtenemos las probabilidades puntuales q_d
    q_d_true = np.zeros(n_delays)
    q_d_true[0] = p_d_cum[0]
    q_d_true[1:] = np.diff(p_d_cum)
    q_d_true /= q_d_true.sum() # Normalización

    # 3. Generamos los reportes (Poisson)
    observaciones = []
    # Simulamos el 'Ahora' en el último día
    fecha_actual_idx = n_days - 1

    for t_idx in range(n_days):
        for d_idx in range(n_delays):
            # Solo generamos el dato si (día ocurrencia + retraso) <= hoy
            if t_idx + d_idx <= fecha_actual_idx:
                # El corazón del modelo: Poisson(Tasa * Prob_Retraso)
                mu = lambda_true[t_idx] * q_d_true[d_idx]
                casos = np.random.poisson(mu)

                observaciones.append({
                    't_idx': t_idx,
                    'd_idx': d_idx,
                    'casos_observados': casos
                })

    return pd.DataFrame(observaciones), lambda_true, b_true, phi_true

# Ejecucion de la Funcion de Generacion de Datos Sintéticos (Simulación de Monte Carlo)
# =============================================================================================================

# Generar la "Verdad Absoluta" (Ground Truth)
# n_days y n_delays se mantienen consistentes con el diseño del estudio (60 y 16)
df_sintetico, lambda_real, b_real, phi_real = generar_datos_sinteticos(n_days=60, n_delays=16)

# Adaptación de variables para PyMC (Analogía con cargar_preparar_datos)
# observations_df será nuestro dataset de entrenamiento sintético
observations_df = df_sintetico
t_len = 60
d_len = 16

# Crear un vector de fechas ficticias para la visualización (opcional, para mantener el formato)
dates = pd.date_range(start="2011-05-07", periods=t_len)

# 3. Reporte de Estructura de Datos
print(f"--- SIMULACIÓN: VALIDACIÓN DE ALGORITMO ---")
print(f"Se generaron {len(observations_df)} observaciones sintéticas.")
print(f"Parámetros fijados (La Verdad): b_true = {b_real}, phi_true = {phi_real}")
print(f"N° de días de ocurrencia (filas): t_len: {t_len}")
print(f"N° de días de atraso (delay) d_len: {d_len}")

print("\nCabecera de Observaciones Sintéticas (Long Format):")
print(observations_df.head(10))

# Función del Modelo Bayesiano (PyMC) - Nowcasting con MCMC (HMC/NUTS)
# -------------------------------------------------------------------------------------------------------------
# Esta función estima la distribución posterior de los casos reales no observados (lambda_t).
#
# Entradas:
#    t_idx_obs:  np.array (int). Vector de índices temporales de ocurrencia [0, T-1].
#                Representa la coordenada 't' de cada observación en el triángulo.
#    d_idx_obs:  np.array (int). Vector de índices de retraso (delay) [0, D-1].
#                Representa el desplazamiento temporal del reporte.
#    y_obs:      np.array (int). Valores observados (conteo de casos) para cada par (t, d).
#                Es el 'target' o variable dependiente del modelo.
#    n_days:     int. Vector que define el horizonte temporal total (T).
#    n_delays:   int. Vector que define el retraso máximo observado (D).
#    es_rw:      (Opcional) Define si se calcula el lam_t como Gamma o como Randon Walk.
#
# Salida:
#    trace:      arviz.InferenceData. Contiene las muestras de la posterior generadas por MCMC.
#                Incluye las distribuciones para lambda_t, phi y b.
# -------------------------------------------------------------------------------------------------------------
#import pymc as pm

def nowcasting_mcmc_hmc(t_idx_obs, d_idx_obs, y_obs, n_days, n_delays, es_rw=False):

  with pm.Model() as model_nowcasting:

        # --- Priors ---
        # phi: Probabilidad de reporte inmediato (Eficiencia Inicial)
        # Definido en el texto como la proporción de casos registrados en d=0.
        # Se usa Uniforme[0,1] por ser una probabilidad, diferenciándose del
        # parámetro de sobre-dispersión de Günther et al. (2021).
        phi = pm.Uniform('phi', lower=0, upper=1)

        # b: Tasa de retraso (Tasa de decaimiento exponencial)
        # Controla la velocidad de reporte. Un prior Exponencial(1.0) asegura
        # valores positivos y una curva de decaimiento monótona.
        b = pm.Exponential('b', lam=1.0)

        lam_t = None
        if es_rw:
          # Mecanismo de reporte basado en Caminata Aleatoria (Günther et al., 2021)
          # Definimos la variabilidad día a día (sigma)
          sigma_lam = pm.Exponential('sigma_lam', lam=1.0)
          # En lugar de Gamma independiente, usamos GaussianRandomWalk
          # Esto conecta algebraicamente lambda[t] con lambda[t-1]
          init_dist = pm.Normal.dist(mu=0.0, sigma=10.0)
          log_lam_t = pm.GaussianRandomWalk('log_lam_t', sigma=sigma_lam, shape=n_days, init_dist=init_dist)
          # Transformamos de escala logarítmica a escala natural (Exponencial)
          # para asegurar que los casos sean siempre positivos
          lam_t = pm.Deterministic('lambda_t', pm.math.exp(log_lam_t))
        else:
          # Prior Gamma para incidencia diaria (Höhle, 2014)
          # Aprovecha la conjugación Poisson-Gamma para estabilidad en la inferencia.
          # lambda_t: Tasa real de casos por día (serie temporal)
          lam_t = pm.Gamma('lambda_t', alpha=1, beta=0.1, shape=n_days)

        # --- Mecanismo de Reporte Paramétrico (Ecuación 2 del informe) ---
        # p(d) acumulada: 1 - (1-phi)*exp(-b*d)
        # Necesitamos calcular q_d (probabilidad puntual) para d=0..15
        d_vals = np.arange(n_delays)

        # Cálculo vectorizado de la acumulada p(d): 1 - (1-phi)*exp(-b*d)
        p_d_cum = 1 - (1 - phi) * pm.math.exp(-b * d_vals)

        # Cálculo de la probabilidad puntual q(d) mediante diferencias discretas
        # q[0] = p[0]
        # q[d] = p[d] - p[d-1]
        q_0 = p_d_cum[0]
        q_rest = p_d_cum[1:] - p_d_cum[:-1]
        q_d_raw = pm.math.concatenate([[q_0], q_rest])

        # Normalización: Garantiza la restricción de cierre (suma de q_d = 1)
        # Esto es crucial porque truncamos los retrasos a 15 días
        q_d = q_d_raw / pm.math.sum(q_d_raw)

        # --- Verosimilitud (Likelihood) ---
        # Se asume estructura de Poisson para priorizar estabilidad numérica
        # sobre modelos de sobre-dispersión complejos en esta etapa.
        mu = lam_t[t_idx_obs] * q_d[d_idx_obs]

        # Observación
        Y_obs = pm.Poisson('Y_obs', mu=mu, observed=y_obs)

        # --- Inferencia (MCMC) ---
        # Implementación de HMC mediante el algoritmo NUTS para resolver la distribución posterior p(theta|y)
        # en espacios de alta dimensionalidad.
        # Aquí intentamos resolver la Distribución Posterior:
        # $$P(\lambda, \phi, b | Y) = \frac{P(Y|\lambda, \phi, b) P(\lambda) P(\phi) P(b)}{\int P(Y|\theta)P(\theta) d\theta}$$
        # El Problema: Esa integral del denominador es imposible de resolver analíticamente en altas dimensiones
        # (tienes cientos de $\lambda$s).
        # Usamos Hamiltonian Monte Carlo (HMC), que devuelve un trace: una colección de 2000 resultados de posibles valores para
        # los parámetros que representan la incertidumbre real del modelo.
        print("Iniciando muestreo MCMC (NUTS)...")
        trace = pm.sample(draws=2000, tune=1000, chains=2, target_accept=0.9, return_inferencedata=True)

        return trace

# Simulacion - Ultima fecha de corte - Sin caminata aleatoria
# -------------------------------------------------------------------------------------------------------------

# n_days y n_delays se mantienen consistentes con el diseño del estudio (60 y 16)
# b_true y phi_true son los valores que el modelo deberia recuperar.
df_sintetico, lambda_real, b_real, phi_real = generar_datos_sinteticos(n_days=60, n_delays=16, b_true=0.15, phi_true=0.2)

# Adaptación de variables para que el resto del código funcione igual
data = df_sintetico
n_days = 60
n_delays = 16
# Creamos fechas ficticias para que el gráfico no falle
dates = pd.date_range(start="2011-05-07", periods=n_days)

# Indices para PyMC (Extraídos del DataFrame sintético)
t_idx_obs = data['t_idx'].values
d_idx_obs = data['d_idx'].values
y_obs = data['casos_observados'].values

print(f"--- SIMULACIÓN: VALIDACIÓN DE ALGORITMO ---")
print(f"Se generaron {len(y_obs)} observaciones sintéticas.")
print(f"La Verdad a recuperar: b={b_real}, phi={phi_real}")

# Ejecutar modelo bayesiano (PyMC) - Usando los datos sintéticos
trace = nowcasting_mcmc_hmc(t_idx_obs, d_idx_obs, y_obs, n_days, n_delays)

# Extraer los limites y medias (Igual que antes)
hdi_lambda = az.hdi(trace.posterior['lambda_t'], hdi_prob=0.95)['lambda_t'].values
casos_reportados_totales = [data[data['t_idx']==i]['casos_observados'].sum() for i in range(n_days)]
posterior_lambda = trace.posterior['lambda_t'].mean(dim=["chain", "draw"]).values

# Crear DataFrame de resultados
results = pd.DataFrame({
    'date': dates,
    'casos_reportados_totales': casos_reportados_totales,
    'estimado_nowcasting': posterior_lambda,
    'lower_ci': hdi_lambda[:, 0],
    'upper_ci': hdi_lambda[:, 1],
    'lambda_real_veridico': lambda_real  # Agregamos la verdad para comparar
})

# Graficar con la "Verdad" incluida
plt.figure(figsize=(12, 6))
plt.plot(results['date'], results['lambda_real_veridico'], label='Verdad (Lambda Real)', color='blue', lw=2, alpha=0.6)
plt.plot(results['date'], results['casos_reportados_totales'], label='Reportados (Sintéticos)', color='black', linestyle='--')
plt.plot(results['date'], results['estimado_nowcasting'], label='Estimado (Nowcasting)', color='firebrick')
plt.fill_between(results['date'], results['lower_ci'], results['upper_ci'], color='firebrick', alpha=0.3, label='Intervalo Credibilidad 95%')

plt.title('Simulación: Validación de Recuperación de Parámetros (HMC/NUTS)')
plt.legend()
plt.show()

# Diagnósticos: Comparar si mean(phi) ~ 0.2 y mean(b) ~ 0.15
print("\nResumen de parámetros globales (Comparar con valores reales):")
print(az.summary(trace, var_names=['phi', 'b']))

# Simulacion - Ultima fecha de corte - Con caminata aleatoria
# -------------------------------------------------------------------------------------------------------------

# n_days y n_delays se mantienen consistentes con el diseño del estudio (60 y 16)
# b_true y phi_true son los valores que el modelo deberia recuperar.
df_sintetico, lambda_real, b_real, phi_real = generar_datos_sinteticos(n_days=60, n_delays=16, b_true=0.15, phi_true=0.2)

# Adaptación de variables para que el resto del código funcione igual
data = df_sintetico
n_days = 60
n_delays = 16
# Creamos fechas ficticias para que el gráfico no falle
dates = pd.date_range(start="2011-05-07", periods=n_days)

# Indices para PyMC (Extraídos del DataFrame sintético)
t_idx_obs = data['t_idx'].values
d_idx_obs = data['d_idx'].values
y_obs = data['casos_observados'].values

print(f"--- SIMULACIÓN: VALIDACIÓN DE ALGORITMO ---")
print(f"Se generaron {len(y_obs)} observaciones sintéticas.")
print(f"La Verdad a recuperar: b={b_real}, phi={phi_real}")

# Ejecutar modelo bayesiano (PyMC) - Usando los datos sintéticos
trace = nowcasting_mcmc_hmc(t_idx_obs, d_idx_obs, y_obs, n_days, n_delays, True)

# Extraer los limites y medias (Igual que antes)
hdi_lambda = az.hdi(trace.posterior['lambda_t'], hdi_prob=0.95)['lambda_t'].values
casos_reportados_totales = [data[data['t_idx']==i]['casos_observados'].sum() for i in range(n_days)]
posterior_lambda = trace.posterior['lambda_t'].mean(dim=["chain", "draw"]).values

# Crear DataFrame de resultados
results = pd.DataFrame({
    'date': dates,
    'casos_reportados_totales': casos_reportados_totales,
    'estimado_nowcasting': posterior_lambda,
    'lower_ci': hdi_lambda[:, 0],
    'upper_ci': hdi_lambda[:, 1],
    'lambda_real_veridico': lambda_real  # Agregamos la verdad para comparar
})

# Graficar con la "Verdad" incluida
plt.figure(figsize=(12, 6))
plt.plot(results['date'], results['lambda_real_veridico'], label='Verdad (Lambda Real)', color='blue', lw=2, alpha=0.6)
plt.plot(results['date'], results['casos_reportados_totales'], label='Reportados (Sintéticos)', color='black', linestyle='--')
plt.plot(results['date'], results['estimado_nowcasting'], label='Estimado (Nowcasting)', color='firebrick')
plt.fill_between(results['date'], results['lower_ci'], results['upper_ci'], color='firebrick', alpha=0.3, label='Intervalo Credibilidad 95%')

plt.title('Simulación: Validación de Recuperación de Parámetros (HMC/NUTS)')
plt.legend()
plt.show()

# Diagnósticos: Comparar si mean(phi) ~ 0.2 y mean(b) ~ 0.15
print("\nResumen de parámetros globales (Comparar con valores reales):")
print(az.summary(trace, var_names=['phi', 'b']))

# Resultados - Ultima fecha de corte - Sin caminata aleatoria
# -------------------------------------------------------------------------------------------------------------

from google.colab import drive
# drive.mount('/content/drive')

# Cargar datos (Asegúrate de tener el archivo en el mismo directorio)
# Simularemos que estamos en el último día del registro
csv_filename = '/content/drive/MyDrive/Colab Datasets/husO104_tri_cumu.csv'

# Invocar la funcion cargar_preparar_datos(): Ultima fecha de corte (fecha con eventos no reportados)
data, n_days, n_delays, dates = cargar_preparar_datos(csv_filename)

# Indices para PyMC
t_idx_obs = data['t_idx'].values
d_idx_obs = data['d_idx'].values
y_obs = data['casos_observados'].values

print(f"Datos cargados: {len(y_obs)} observaciones válidas para el triángulo de reporte.")

# Ejecutar modelo bayesiano (PyMC) - Nowcasting con MCMC (HMC/NUTS)
trace = nowcasting_mcmc_hmc(t_idx_obs, d_idx_obs, y_obs, n_days, n_delays)

# Extraer los limites del resultado (lower y upper)
hdi_lambda = az.hdi(trace.posterior['lambda_t'], hdi_prob=0.95)['lambda_t'].values

# Extraer medias posteriores de lambda (Casos Reales Estimados)
casos_reportados_totales = [data[data['t_idx']==i]['casos_observados'].sum() for i in range(n_days)]
posterior_lambda = trace.posterior['lambda_t'].mean(dim=["chain", "draw"]).values

# Crear DataFrame de resultados
results = pd.DataFrame({
    'date': dates,
    'casos_reportados_totales': casos_reportados_totales,
    'estimado_nowcasting': posterior_lambda,
    'lower_ci': hdi_lambda[:, 0],
    'upper_ci': hdi_lambda[:, 1]
})

print("\n--- Resultados (Últimos 10 días) ---")
print(results.tail(10))

# Graficar
plt.figure(figsize=(12, 6))
plt.plot(results['date'], results['casos_reportados_totales'], label='Reportados (Actuales)', color='black', linestyle='--')
plt.plot(results['date'], results['estimado_nowcasting'], label='Estimado (Nowcasting)', color='firebrick')
plt.fill_between(results['date'], results['lower_ci'], results['upper_ci'], color='firebrick', alpha=0.3, label='Intervalo Credibilidad 95%')

plt.title('Hamiltonian Monte Carlo - Nowcasting de Casos E. Coli (Estimación vs Reportados)')
plt.xlabel('Fecha')
plt.ylabel('Número de Casos')
plt.legend()
plt.grid(True, alpha=0.3)
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
plt.show()

# Diagnósticos básicos
print("\nResumen de parámetros globales:")
print(az.summary(trace, var_names=['phi', 'b']))

# Resultados y Visualización - Mitad de fecha (para validacion del modelo) - Sin caminata aleatoria
# -------------------------------------------------------------------------------------------------------------

from google.colab import drive
# drive.mount('/content/drive')

# Cargar datos (Asegúrate de tener el archivo en el mismo directorio)
# Simularemos que estamos en el último día del registro
csv_filename = '/content/drive/MyDrive/Colab Datasets/husO104_tri_cumu.csv'

# Invocar la funcion cargar_preparar_datos(): Mitad de fecha (para validacion del modelo)
fecha_mitad_corte = pd.to_datetime('2011-06-06')
data, n_days, n_delays, dates = cargar_preparar_datos(csv_filename, fecha_actual=fecha_mitad_corte)

# Indices para PyMC
t_idx_obs = data['t_idx'].values
d_idx_obs = data['d_idx'].values
y_obs = data['casos_observados'].values

print(f"Datos cargados: {len(y_obs)} observaciones válidas para el triángulo de reporte.")

# Ejecutar modelo bayesiano (PyMC) - Nowcasting con MCMC (HMC/NUTS)
trace = nowcasting_mcmc_hmc(t_idx_obs, d_idx_obs, y_obs, n_days, n_delays)

# Extraer los limites del resultado (lower y upper)
hdi_lambda = az.hdi(trace.posterior['lambda_t'], hdi_prob=0.95)['lambda_t'].values

# Extraer medias posteriores de lambda (Casos Reales Estimados)
casos_reportados_totales = [data[data['t_idx']==i]['casos_observados'].sum() for i in range(n_days)]
posterior_lambda = trace.posterior['lambda_t'].mean(dim=["chain", "draw"]).values

# Crear DataFrame de resultados
results = pd.DataFrame({
    'date': dates,
    'casos_reportados_totales': casos_reportados_totales,
    'estimado_nowcasting': posterior_lambda,
    'lower_ci': hdi_lambda[:, 0],
    'upper_ci': hdi_lambda[:, 1]
})

print("\n--- Resultados (Últimos 10 días) ---")
print(results.tail(10))

# Graficar
plt.figure(figsize=(12, 6))
plt.plot(results['date'], results['casos_reportados_totales'], label='Reportados (Actuales)', color='black', linestyle='--')
plt.plot(results['date'], results['estimado_nowcasting'], label='Estimado (Nowcasting)', color='firebrick')
plt.fill_between(results['date'], results['lower_ci'], results['upper_ci'], color='firebrick', alpha=0.3, label='Intervalo Credibilidad 95%')

plt.title('Hamiltonian Monte Carlo - Nowcasting de Casos E. Coli (Estimación vs Reportados)')
plt.xlabel('Fecha')
plt.ylabel('Número de Casos')
plt.legend()
plt.grid(True, alpha=0.3)
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
plt.show()

# Diagnósticos básicos
print("\nResumen de parámetros globales:")
print(az.summary(trace, var_names=['phi', 'b']))

# Resultados - Ultima fecha de corte - Sin caminata aleatoria
# -------------------------------------------------------------------------------------------------------------

from google.colab import drive
# drive.mount('/content/drive')

# Cargar datos (Asegúrate de tener el archivo en el mismo directorio)
# Simularemos que estamos en el último día del registro
csv_filename = '/content/drive/MyDrive/Colab Datasets/husO104_tri_cumu.csv'

# Invocar la funcion cargar_preparar_datos(): Ultima fecha de corte (fecha con eventos no reportados)
data, n_days, n_delays, dates = cargar_preparar_datos(csv_filename)

# Indices para PyMC
t_idx_obs = data['t_idx'].values
d_idx_obs = data['d_idx'].values
y_obs = data['casos_observados'].values

print(f"Datos cargados: {len(y_obs)} observaciones válidas para el triángulo de reporte.")

# Ejecutar modelo bayesiano (PyMC) - Nowcasting con MCMC (HMC/NUTS)
trace = nowcasting_mcmc_hmc(t_idx_obs, d_idx_obs, y_obs, n_days, n_delays, True)

# Extraer los limites del resultado (lower y upper)
hdi_lambda = az.hdi(trace.posterior['lambda_t'], hdi_prob=0.95)['lambda_t'].values

# Extraer medias posteriores de lambda (Casos Reales Estimados)
casos_reportados_totales = [data[data['t_idx']==i]['casos_observados'].sum() for i in range(n_days)]
posterior_lambda = trace.posterior['lambda_t'].mean(dim=["chain", "draw"]).values

# Crear DataFrame de resultados
results = pd.DataFrame({
    'date': dates,
    'casos_reportados_totales': casos_reportados_totales,
    'estimado_nowcasting': posterior_lambda,
    'lower_ci': hdi_lambda[:, 0],
    'upper_ci': hdi_lambda[:, 1]
})

print("\n--- Resultados (Últimos 10 días) ---")
print(results.tail(10))

# Graficar
plt.figure(figsize=(12, 6))
plt.plot(results['date'], results['casos_reportados_totales'], label='Reportados (Actuales)', color='black', linestyle='--')
plt.plot(results['date'], results['estimado_nowcasting'], label='Estimado (Nowcasting)', color='firebrick')
plt.fill_between(results['date'], results['lower_ci'], results['upper_ci'], color='firebrick', alpha=0.3, label='Intervalo Credibilidad 95%')

plt.title('Hamiltonian Monte Carlo - Nowcasting de Casos E. Coli (Estimación vs Reportados)')
plt.xlabel('Fecha')
plt.ylabel('Número de Casos')
plt.legend()
plt.grid(True, alpha=0.3)
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
plt.show()

# Diagnósticos básicos
print("\nResumen de parámetros globales:")
print(az.summary(trace, var_names=['phi', 'b']))